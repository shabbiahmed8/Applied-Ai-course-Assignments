{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9464I-uxLiw"
      },
      "source": [
        "# Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg2ooa4DxLiz"
      },
      "source": [
        "## Task-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnV82tg1xLi0"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUsYm9wjxLi1"
      },
      "source": [
        "## SkLearn# Collection of string documents\n",
        "\n",
        "corpus = [\n",
        "     'this is the first document',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document',\n",
        "]"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLwmFZfKxLi4"
      },
      "source": [
        "### SkLearn Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np4dfQOkxLi4"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(corpus)\n",
        "skl_output = vectorizer.transform(corpus)"
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7Om8YpYxLi6",
        "outputId": "0c39f311-f4b8-4115-e0e3-ed0eaa7dc1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# sklearn feature names, they are sorted in alphabetic order by default.\n",
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTKplK96xLi-",
        "outputId": "8fb09d7c-e7d2-43b2-e4dd-635a5433d47b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Here we will print the sklearn tfidf vectorizer idf values after applying the fit method\n",
        "# After using the fit function on the corpus the vocab has 9 words in it, and each has its idf value.\n",
        "\n",
        "print(vectorizer.idf_)"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
            " 1.         1.91629073 1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CTiWHygxLjA",
        "outputId": "4d3410a3-199f-4db5-c9c2-755241cd7f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# shape of sklearn tfidf vectorizer output after applying transform method.\n",
        "skl_output.shape"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDKEpbA-xLjD",
        "outputId": "2deff9a8-7be5-4dcb-8f2c-af34167e3938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# sklearn tfidf values for first line of the above corpus.\n",
        "# Here the output is a sparse matrix\n",
        "print(skl_output[0])"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QWo34hexLjF",
        "outputId": "31439ac9-df53-4d53-c22f-5d11608ceddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# sklearn tfidf values for first line of the above corpus.\n",
        "# To understand the output better, here we are converting the sparse output matrix to dense matrix and printing it.\n",
        "# Notice that this output is normalized using L2 normalization. sklearn does this by default.\n",
        "print(skl_output[0].toarray())"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfIwx5LzxLjI"
      },
      "source": [
        "### Your custom implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjuCcJwXxLjJ"
      },
      "source": [
        "# Write your code here.\n",
        "# Make sure its well documented and readble with appropriate comments.\n",
        "# Compare your results with the above sklearn tfidf vectorizer\n",
        "# You are not supposed to use any other library apart from the ones given below\n",
        "\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(data):# returns vocab{word:index} and idf{word:idf} dictionaries with words as keys\n",
        "  unq_words = set() #set to store all unique words\n",
        "  vocab = dict() #dict to store words and indexes\n",
        "  idf = dict() # dict to store words and idf values\n",
        "\n",
        "\n",
        "  if isinstance(data, list):# chesking if input data is list\n",
        "    for doc in data:  # looping to find all the unique words and storing\n",
        "      for word in doc.split():\n",
        "        unq_words.add(word)\n",
        "    unq_words = sorted(list(unq_words)) # list of sorted unique words\n",
        "\n",
        "    for wrd in unq_words: # calculating idf for every word and storing in dict\n",
        "      counts = 0\n",
        "      for docs in data:\n",
        "        if wrd in docs.split():\n",
        "          counts += 1\n",
        "      idf[wrd] = 1+math.log((len(data)+1)/(counts+1)) #calculating idf using sk_learn formula given\n",
        "      \n",
        "    \n",
        "    vocab = {j:i for i,j in enumerate(unq_words)}  #dict of words and indexes from unq_words list\n",
        "\n",
        "\n",
        "    return vocab,idf\n",
        "  else:\n",
        "    return \"input must be a list of strings\""
      ],
      "metadata": {
        "id": "dnu-avVcISun"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab , idf = fit(corpus)\n",
        "print(vocab.keys()) #list of sorted unique words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "73fZoyAKLbBG",
        "outputId": "fb3a8e81-f1f7-47c4-97e0-4ebac241f832"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf.keys() # list of sorted unique words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Zwk6A6vONIAi",
        "outputId": "a58b6741-0328-46cb-ff90-9ee990966910"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this'])"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list of IDF values corresponding to unique words\n",
        "idf.values() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bqwNoAAVXBLr",
        "outputId": "1d3ddbfb-5e11-428e-f047-a8a075f30f21"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([1.916290731874155, 1.2231435513142097, 1.5108256237659907, 1.0, 1.916290731874155, 1.916290731874155, 1.0, 1.916290731874155, 1.0])"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trans(data, vocab,idf): # returns sparse matrix of tfidf values\n",
        "  rows = []\n",
        "  columns = []\n",
        "  values = []\n",
        " \n",
        "  if isinstance(data, (list,)): # cheskinng type of input is list\n",
        "    for idx, row in enumerate(data): \n",
        "      word_freq = dict(Counter(row.split())) # it will return a dict type object where key is the word and values is its frequency, {word:frequency}\n",
        "      for word, freq in word_freq.items():  # for each unique word in the review.                \n",
        "                \n",
        "                # we will check if its there in the vocabulary that we build in fit() function\n",
        "                # dict.get() function will return the values, if the key doesn't exits it will return -1\n",
        "                col_index = vocab.get(word,-1) # retreving the dimension number of a word\n",
        "                \n",
        "                # if the word exists\n",
        "                if col_index !=-1:\n",
        "                    # we are storing the index of the document\n",
        "                    rows.append(idx)\n",
        "                    # we are storing the dimensions of the word\n",
        "                    columns.append(col_index)\n",
        "                    # we are storing the frequency of the word\n",
        "                    values.append(freq/len(row.split())*idf[word]) #storing tfidf value\n",
        "    \n",
        "\n",
        "    return csr_matrix((values, (rows,columns)), shape=(len(data),len(vocab)))\n",
        "  else:\n",
        "        print(\"you need to pass list of strings\")"
      ],
      "metadata": {
        "id": "2qqxmEBogkxk"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf = trans(corpus,vocab, idf) #returns a sparse matrix of tfidf"
      ],
      "metadata": {
        "id": "JqYmr1qpNPXy"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf.shape # shape of the tf_idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VAABQQvCOFom",
        "outputId": "05833c76-b9b7-408b-ff09-85ecd464e254"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf_idf[0])  # sparse matrix before normalization for first line in the corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vrki2GT8OI5N",
        "outputId": "567e1e68-5e28-432f-96e9-1dc0e6813d6b"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1)\t0.24462871026284194\n",
            "  (0, 2)\t0.3021651247531982\n",
            "  (0, 3)\t0.2\n",
            "  (0, 6)\t0.2\n",
            "  (0, 8)\t0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_tfidf = normalize(tf_idf) # normalizing the sparse matrix"
      ],
      "metadata": {
        "id": "Wl3WyN_fSFQE"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(norm_tfidf[0]) # normalized tfidf sparse matrix for first line in corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "C_s8n3JmSyBh",
        "outputId": "ba4b57f9-aef6-410c-d16c-55352b64b4f7"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1)\t0.4697913855799205\n",
            "  (0, 2)\t0.580285823684436\n",
            "  (0, 3)\t0.3840852409148149\n",
            "  (0, 6)\t0.3840852409148149\n",
            "  (0, 8)\t0.3840852409148149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(skl_output[0]) # scikit learn output of first line in corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lz5a4jfjTTRq",
        "outputId": "28041f66-551f-46b8-cc80-8f0ae430d6e5"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMxBmVZExLjK"
      },
      "source": [
        "## Task-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHxPLlwNxLjL",
        "outputId": "6cf34b47-bb79-4f29-acfc-118bbb7629b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Below is the code to load the cleaned_strings pickle file provided\n",
        "# Here corpus is of list type\n",
        "\n",
        "import pickle\n",
        "with open('cleaned_strings', 'rb') as f:\n",
        "    corpus_1 = pickle.load(f)\n",
        "    \n",
        "# printing the length of the corpus loaded\n",
        "print(\"Number of documents in corpus = \",len(corpus_1))"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents in corpus =  746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_50(data):# returns np array with sorted unique words index and idf values \n",
        "  unq_words = set() #empty set for unique words in the data\n",
        "  vocab = dict() #dict to store wrods and respective index\n",
        "  idf = dict() #dict to store words and corresponding idf values\n",
        "\n",
        "\n",
        "  if isinstance(data, list):\n",
        "\n",
        "    # gettting all unique words\n",
        "    for doc in data:\n",
        "      for word in doc.split():\n",
        "        unq_words.add(word)\n",
        "    unq_words = sorted(list(unq_words))\n",
        "\n",
        "\n",
        "    # idf for each word\n",
        "    for wrd in unq_words:\n",
        "      counts = 0\n",
        "      for docs in data:\n",
        "        if wrd in docs.split():\n",
        "          counts += 1\n",
        "      idf[wrd] = 1+math.log((len(data)+1)/(counts+1))\n",
        "\n",
        "    #top 50 idfs and corresponding words as keys\n",
        "    top_50_idf = {k: v for k,v in sorted(idf.items(),reverse =True, key = lambda tup : tup[1])[0:50]}\n",
        "\n",
        "    # vocab dict for top_50 idf words and their index as values {word:index}\n",
        "    vocab = {k:ind for ind,k in enumerate(list(top_50_idf.keys()))}\n",
        "\n",
        "\n",
        "    return vocab,top_50_idf\n",
        "  else:\n",
        "    return \"input must be a list of strings\""
      ],
      "metadata": {
        "id": "9XuIZpSUkn9_"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab , idf = fit_50(corpus_1) # dicts with vocab and idf values of top 50 idf valued words"
      ],
      "metadata": {
        "id": "eUvGRaac0S-j"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zL7-HbO_KJ0Q",
        "outputId": "d24c4915-62bb-4b54-b8f5-508d775d99c9"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'aailiyah': 0,\n",
              " 'abandoned': 1,\n",
              " 'abroad': 2,\n",
              " 'abstruse': 3,\n",
              " 'academy': 4,\n",
              " 'accents': 5,\n",
              " 'accessible': 6,\n",
              " 'acclaimed': 7,\n",
              " 'accolades': 8,\n",
              " 'accurate': 9,\n",
              " 'accurately': 10,\n",
              " 'achille': 11,\n",
              " 'ackerman': 12,\n",
              " 'actions': 13,\n",
              " 'adams': 14,\n",
              " 'add': 15,\n",
              " 'added': 16,\n",
              " 'admins': 17,\n",
              " 'admiration': 18,\n",
              " 'admitted': 19,\n",
              " 'adrift': 20,\n",
              " 'adventure': 21,\n",
              " 'aesthetically': 22,\n",
              " 'affected': 23,\n",
              " 'affleck': 24,\n",
              " 'afternoon': 25,\n",
              " 'aged': 26,\n",
              " 'ages': 27,\n",
              " 'agree': 28,\n",
              " 'agreed': 29,\n",
              " 'aimless': 30,\n",
              " 'aired': 31,\n",
              " 'akasha': 32,\n",
              " 'akin': 33,\n",
              " 'alert': 34,\n",
              " 'alike': 35,\n",
              " 'allison': 36,\n",
              " 'allow': 37,\n",
              " 'allowing': 38,\n",
              " 'alongside': 39,\n",
              " 'amateurish': 40,\n",
              " 'amaze': 41,\n",
              " 'amazed': 42,\n",
              " 'amazingly': 43,\n",
              " 'amusing': 44,\n",
              " 'amust': 45,\n",
              " 'anatomist': 46,\n",
              " 'angel': 47,\n",
              " 'angela': 48,\n",
              " 'angelina': 49}"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xyCu-jV7QsqL",
        "outputId": "63e90f4c-a277-407e-d384-36d0e4957596"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'aailiyah': 6.922918004572872,\n",
              " 'abandoned': 6.922918004572872,\n",
              " 'abroad': 6.922918004572872,\n",
              " 'abstruse': 6.922918004572872,\n",
              " 'academy': 6.922918004572872,\n",
              " 'accents': 6.922918004572872,\n",
              " 'accessible': 6.922918004572872,\n",
              " 'acclaimed': 6.922918004572872,\n",
              " 'accolades': 6.922918004572872,\n",
              " 'accurate': 6.922918004572872,\n",
              " 'accurately': 6.922918004572872,\n",
              " 'achille': 6.922918004572872,\n",
              " 'ackerman': 6.922918004572872,\n",
              " 'actions': 6.922918004572872,\n",
              " 'adams': 6.922918004572872,\n",
              " 'add': 6.922918004572872,\n",
              " 'added': 6.922918004572872,\n",
              " 'admins': 6.922918004572872,\n",
              " 'admiration': 6.922918004572872,\n",
              " 'admitted': 6.922918004572872,\n",
              " 'adrift': 6.922918004572872,\n",
              " 'adventure': 6.922918004572872,\n",
              " 'aesthetically': 6.922918004572872,\n",
              " 'affected': 6.922918004572872,\n",
              " 'affleck': 6.922918004572872,\n",
              " 'afternoon': 6.922918004572872,\n",
              " 'aged': 6.922918004572872,\n",
              " 'ages': 6.922918004572872,\n",
              " 'agree': 6.922918004572872,\n",
              " 'agreed': 6.922918004572872,\n",
              " 'aimless': 6.922918004572872,\n",
              " 'aired': 6.922918004572872,\n",
              " 'akasha': 6.922918004572872,\n",
              " 'akin': 6.922918004572872,\n",
              " 'alert': 6.922918004572872,\n",
              " 'alike': 6.922918004572872,\n",
              " 'allison': 6.922918004572872,\n",
              " 'allow': 6.922918004572872,\n",
              " 'allowing': 6.922918004572872,\n",
              " 'alongside': 6.922918004572872,\n",
              " 'amateurish': 6.922918004572872,\n",
              " 'amaze': 6.922918004572872,\n",
              " 'amazed': 6.922918004572872,\n",
              " 'amazingly': 6.922918004572872,\n",
              " 'amusing': 6.922918004572872,\n",
              " 'amust': 6.922918004572872,\n",
              " 'anatomist': 6.922918004572872,\n",
              " 'angel': 6.922918004572872,\n",
              " 'angela': 6.922918004572872,\n",
              " 'angelina': 6.922918004572872}"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf_1 = trans(corpus_1, vocab,idf) # returns sparse matrix of coulmn size 50"
      ],
      "metadata": {
        "id": "6IuRITL8JJw7"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf_idf_1[0]) # sparse vector of first doc in corpus before normalization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XWdCH0oqL8dz",
        "outputId": "59fc8731-ef04-41ad-a934-4bd82a1c3fa9"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 30)\t0.865364750571609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_1[0] #first doc in corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zbdmzjpDMioG",
        "outputId": "0db06e11-5ed3-45c5-fb0d-c73b897c67e1"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'slow moving aimless movie distressed drifting young man'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It has only one word \"aimless\" that is present in vocab"
      ],
      "metadata": {
        "id": "JTucCbkoV6A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_tfidf = normalize(tf_idf_1) # normalizing the sparse matrix"
      ],
      "metadata": {
        "id": "nu8BQosqNxrG"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(norm_tfidf[0].toarray()) # prints norm_sparse veector of first doc with 50 features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V2Wk3DkzRs1u",
        "outputId": "0cde0037-d82d-4b22-eff6-399414a812b7"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><center><b>End of the Document"
      ],
      "metadata": {
        "id": "8-dDnDSLYApJ"
      }
    }
  ]
}